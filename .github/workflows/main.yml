# create a workflow that runs scrape.py once every hour
name: Hourly Scraper

# Trigger the workflow every hour
on:
  schedule:
    - cron: "0 * * * *"

# also support manual triggering


jobs:
  run-scraper:
    runs-on: ubuntu-latest
    steps:
      # Checkout the repository so that we have access to the Python script
      - name: Check out the code
        uses: actions/checkout@v3

      # Set up Python environment
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.x'  # Specify your required Python version

      # Install dependencies (if any)
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          if [ -f requirements.txt ]; then pip install -r requirements.txt; fi

      # Run the Python script
      - name: Run cron.py
        env:
          GOOGLE_API_KEY: ${{ secrets.GOOGLE_API_KEY }}
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
        run: python cron.py
